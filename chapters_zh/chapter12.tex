\chapter{BLAST}
\label{chap:chapter12}
\minitoc

In biological research, the search for sequence similarity is very important. For instance, a researcher who has discovered a potentially important DNA or protein sequence wants to know if it's already been identified and characterized by another researcher. If it hasn't, the researcher wants to know if it resembles any known sequence from any organism. This information can provide vital clues as to the role of the sequence in the organism.

The Basic Local Alignment Search Tool (BLAST) is one of the most popular software tools in biological research. It tests a query sequence against a library of known sequences in order to find similarity. BLAST is actually a collection of programs with versions for query-to-database pairs such as nucleotide-nucleotide, protein-nucleotide, protein-protein, nucleotide-protein, and more.

This chapter examines the output from the nucleotide-nucleotide version of the program, \textit{BLASTN}. For simplicity's sake, I'll simply refer to it here as BLAST. The main goal of this chapter is to show how to write code to parse a BLAST output file using regular expressions. The code is simple and basic, but it does the job. Once you understand the basics, you can build more features into your parser or obtain one of the fancier BLAST output parsers that's available via the Web. In either case, you'll know enough about output parsers to use or extend them.

This chapter also gives you a brief introduction to Bioperl, which is a collection of Perl bioinformatics modules. The Bioperl project is an example of an open source project that you, the Perl bioinformatics programmer, can put to good use. The Perl programming language is itself an open source project. The program and its source code are available for use and modification with only very reasonable restrictions and at no cost.

\section{Obtaining BLAST}
There are a several implementations of BLAST. The most popular is probably the one offered free of charge by the National Center for Biotechnology Information (NCBI): \href{http://www.ncbi.nlm.nih.gov/BLAST/}{http://www.ncbi.nlm.nih.gov/BLAST/}. The NCBI web site features a publicly available BLAST server, a comprehensive set of databases, and a well-organized collection of documents and tutorials, in addition to the BLAST software available for downloading.

Also popular is the WU-BLAST implementation from Washington University. The main web site, including a list of other WU-BLAST servers, can be found at \href{http://blast.wustl.edu}{http://blast.wustl.edu}. Older versions of WU-BLAST are available at no charge. Newer versions are free if you qualify as a research or nonprofit organization and agree to the licensing arrangements from Washington University where the program is developed and maintained. If you work at a major research organization, you may already have a site license for the WU-BLAST program. If you are a for-profit company, there is a rather hefty charge for the newer WU-BLAST program (older versions are freely available if you want to run BLAST on your own computer). Pennsylvania State University also develops some BLAST programs, available at \href{http://bio.cse.psu.edu/}{http://bio.cse.psu.edu/}. In addition to NCBI and WU-BLAST, many other BLAST server web sites are available. A Google search (\href{http://www.google.com}{http://www.google.com}) on "BLAST server" will bring up many hits.

A big question that faces researchers when they use BLAST is whether to use a public BLAST server or to run it locally. There are significant advantages to using a public server, the largest being that the databases (such as GenBank) used by the BLAST server are always up to date. To keep your own up-to-date copy of these databases requires a significant amount of hard-disk space, a computer with a fairly high-end processor and a lot of memory (to run the BLAST engine), a high-capacity network link, and a lot of time setting up and overseeing the software that updates the databases. On the other hand, perhaps you have your own library of sequences that you want to use in BLAST searches, you do frequent or large searches, or you have other reasons to run your own in-house BLAST engine. If that's the case, it makes sense to invest in the hardware and run it locally.

The online documentation for BLAST is fairly extensive and includes details on the statistical methods the program uses to calculate similarity. In the next section, I touch briefly on some of those points, but you should refer to the BLAST home page and to the excellent material at the NCBI web site for the whole story and detailed references. Our interest here is not the theory, but rather to parse the output of the program. 

\section{String Matching and Homology}
\textit{String matching} is the computer-science term for algorithms that find one string embedded in another. It has a fairly long and fruitful history, and many string-matching algorithms have been developed using a variety of techniques and for different cases. (See the Gusfield book in \autoref{chap:chapteraa} for an excellent treatment with a biological emphasis.) We've already done a fair amount of string matching, using the binding operator to search for motifs and other text with regular expressions.

BLAST is basically a string-matching program. Details of the string-matching algorithms, and of the algorithms used in BLAST in particular, are beyond the scope of this book. But first I want to define some terms that are frequently confused or used interchangeably.  I also briefly introduce the BLAST statistics.

Biological string matching looks for similarity as an indication of homology. \textit{Similarity} between the query and the sequences in the database may be measured by the \textit{percent identity}, or the number of bases in the query that exactly match a corresponding region of a sequence from the database. It may also be measured by the degree of \textit{conservation}, which finds matches between equivalent (redundant) codons or between amino acid residues with similar properties that don't alter the function of a protein (see \autoref{chap:chapter8}). \textit{Homology} between sequences means the sequences are related evolutionarily. Two sequences are or are not homologous; there's no degree of homology.

At the risk of oversimplifying a complex topic, I'll summarize a few facts about BLAST statistics. (See the BLAST documentation for a complete picture.) The output of a BLAST search reports a set of scores and statistics on the matches it has found based on the raw score S, various parameters of the scoring algorithm, and properties of the query and database. The \textit{raw score S} is a measure of similarity and the size of the match. The BLAST output lists the hits ranked by their E value. The \textit{E (expect) value} of a match measures, roughly, the chances that the string matching (allowing for gaps) occurs in a randomly generated database of the same size and composition. The closer to 0 the E value is, the less likely it occurred by chance. In other words, the lower the E value, the better the match. As a general rule of thumb for BLASTN, an E value less than 1 may be a solid hit, and an E value of less than 10 may be worth looking at, but this is not a hard and fast rule. (Of course, proteins can be homologous with even a very small percent identity; the percent similarity is typically higher for homologous DNA.)

Now that you have the basics, let's write code to parse BLAST output. First, you separate the hits, then extract the sequence, and finally, you find the annotation showing the E value statistic. 

\section{BLAST Output Files}
The following is part of a BLAST output file. I created it by entering a few lines of the \textit{sample.dna} file from \autoref{chap:chapter8} into the BLAST program at the NCBI web site, without changing any of the default parameters. I then saved the output as text in the file \textit{blst.txt}, which is available from this book's web site. I've used it repeatedly in the parsing routines throughout this chapter. Because the output is several pages long, I've truncated it here to show the beginning, the middle, and the end of the file. 

\begin{lstlisting}
BLASTN 2.1.3 [Apr-11-2001]

Reference: Altschul, Stephen F., Thomas L. Madden, Alejandro A. Schaffer,
Jinghui Zhang, Zheng Zhang, Webb Miller, and David J. Lipman (1997),
"Gapped BLAST and PSI-BLAST: a new generation of protein database search
programs",  Nucleic Acids Res. 25:3389-3402.
RID: 991533563-27495-9092
Query=
         (400 letters)

Database: nt
           868,831 sequences; 3,298,558,333 total letters

                                                                   Score     E
Sequences producing significant alignments:                        (bits)  Value

dbj|AB031069.1|AB031069 Homo sapiens PCCX1 mRNA for protein cont...   793  0.0
ref|NM_014593.1| Homo sapiens CpG binding protein (CGBP), mRNA        779  0.0
gb|AF149758.1|AF149758 Homo sapiens CpG binding protein (CGBP) m...   779  0.0
ref|XM_008699.3| Homo sapiens CpG binding protein (CGBP), mRNA        765  0.0
emb|AL136862.1|HSM801830 Homo sapiens mRNA; cDNA DKFZp434F174 (f...   450  e-124
emb|AJ132339.1|HSA132339 Homo sapiens CpG island sequence, subcl...   446  e-123
emb|AJ236590.1|HSA236590 Homo sapiens chromosome 18 CpG island D...   406  e-111
dbj|AK010337.1|AK010337 Mus musculus ES cells cDNA, RIKEN full-l...   234  3e-59
dbj|AK017941.1|AK017941 Mus musculus adult male thymus cDNA, RIK...   210  5e-52
gb|AC009750.7|AC009750 Drosophila melanogaster, chromosome 2L, r...    46  0.017
gb|AE003580.2|AE003580 Drosophila melanogaster genomic scaffold ...    46  0.017
ref|NC_001905.1| Leishmania major chromosome 1, complete sequence      40  1.0
gb|AE001274.1|AE001274 Leishmania major chromosome 1, complete s...    40  1.0
gb|AC008299.5|AC008299 Drosophila melanogaster, chromosome 3R, r...    38  4.1
gb|AC018662.3|AC018662 Human Chromosome 7 clone RP11-339C9, comp...    38  4.1
gb|AE003774.2|AE003774 Drosophila melanogaster genomic scaffold ...    38  4.1
gb|AC008039.1|AC008039 Homo sapiens clone SCb-391H5 from 7q31, c...    38  4.1
gb|AC005315.2|AC005315 Arabidopsis thaliana chromosome II sectio...    38  4.1
emb|AL353748.13|AL353748 Human DNA sequence from clone RP11-317B...    38  4.1

ALIGNMENTS
>dbj|AB031069.1|AB031069 Homo sapiens PCCX1 mRNA for protein containing CXXC
domain 1,
           complete cds
          Length = 2487

 Score =  793 bits (400), Expect = 0.0
 Identities = 400/400 (100%)
 Strand = Plus / Plus

Query: 1   agatggcggcgctgaggggtcttgggggctctaggccggccacctactggtttgcagcgg 60
           ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Sbjct: 1   agatggcggcgctgaggggtcttgggggctctaggccggccacctactggtttgcagcgg 60

Query: 61  agacgacgcatggggcctgcgcaataggagtacgctgcctgggaggcgtgactagaagcg 120
           ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Sbjct: 61  agacgacgcatggggcctgcgcaataggagtacgctgcctgggaggcgtgactagaagcg 120

Query: 121 gaagtagttgtgggcgcctttgcaaccgcctgggacgccgccgagtggtctgtgcaggtt 180
           ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Sbjct: 121 gaagtagttgtgggcgcctttgcaaccgcctgggacgccgccgagtggtctgtgcaggtt 180

Query: 181 cgcgggtcgctggcgggggtcgtgagggagtgcgccgggagcggagatatggagggagat 240
           ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Sbjct: 181 cgcgggtcgctggcgggggtcgtgagggagtgcgccgggagcggagatatggagggagat 240

Query: 241 ggttcagacccagagcctccagatgccggggaggacagcaagtccgagaatggggagaat 300
           ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Sbjct: 241 ggttcagacccagagcctccagatgccggggaggacagcaagtccgagaatggggagaat 300

Query: 301 gcgcccatctactgcatctgccgcaaaccggacatcaactgcttcatgatcgggtgtgac 360
           ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Sbjct: 301 gcgcccatctactgcatctgccgcaaaccggacatcaactgcttcatgatcgggtgtgac 360

Query: 361 aactgcaatgagtggttccatggggactgcatccggatca 400
           ||||||||||||||||||||||||||||||||||||||||
Sbjct: 361 aactgcaatgagtggttccatggggactgcatccggatca 400

>ref|NM_014593.1| Homo sapiens CpG binding protein (CGBP), mRNA

 ... (file truncated here)



>dbj|AK010337.1|AK010337 Mus musculus ES cells cDNA, RIKEN full-length
enriched library,
           clone:2410002I16, full insert sequence
          Length = 2538

 Score =  234 bits (118), Expect = 3e-59
 Identities = 166/182 (91%)
 Strand = Plus / Plus

Query: 219 gagcggagatatggagggagatggttcagacccagagcctccagatgccggggaggacag 278
           ||||||||||||||| |||||||| |||||||  || ||||| ||||||||||| |||||
Sbjct: 260 gagcggagatatggaaggagatggctcagacctggaacctccggatgccggggacgacag 319

Query: 279 caagtccgagaatggggagaatgcgcccatctactgcatctgccgcaaaccggacatcaa 338
           |||||| |||||||||||||| || ||||||||||||||||| |||||||||||||||||
Sbjct: 320 caagtctgagaatggggagaacgctcccatctactgcatctgtcgcaaaccggacatcaa 379

Query: 339 ctgcttcatgatcgggtgtgacaactgcaatgagtggttccatggggactgcatccggat 398
            ||||||||||| || |||||||||||||| |||||||||||||| ||||||||||||||
Sbjct: 380 ttgcttcatgattggatgtgacaactgcaacgagtggttccatggagactgcatccggat 439

Query: 399 ca 400
           ||
Sbjct: 440 ca 441
 Score = 44.1 bits (22), Expect = 0.066
 Identities = 25/26 (96%)
 Strand = Plus / Plus

Query: 118 gcggaagtagttgtgggcgcctttgc 143
           ||||||||||||| ||||||||||||
Sbjct: 147 gcggaagtagttgcgggcgcctttgc 172

>dbj|AK017941.1|AK017941 Mus musculus adult male thymus cDNA, RIKEN
full-length enriched library, clone:5830420C16, full insert sequence
          Length = 1461

 Score =  210 bits (106), Expect = 5e-52
 Identities = 151/166 (90%)
 Strand = Plus / Plus

Query: 235  ggagatggttcagacccagagcctccagatgccggggaggacagcaagtccgagaatggg 294
            |||||||| |||||||  || ||||| ||||||||||| ||||||||||| |||||||||
Sbjct: 1048 ggagatggctcagacctggaacctccggatgccggggacgacagcaagtctgagaatggg 1107

Query: 295  gagaatgcgcccatctactgcatctgccgcaaaccggacatcaactgcttcatgatcggg 354
            ||||| || ||||||||||||||||| ||||||||||||||||| ||||||||||| ||
Sbjct: 1108 gagaacgctcccatctactgcatctgtcgcaaaccggacatcaattgcttcatgattgga 1167

Query: 355  tgtgacaactgcaatgagtggttccatggggactgcatccggatca 400
            |||||||||||||| |||||||||||||| ||||||||||||||||
Sbjct: 1168 tgtgacaactgcaacgagtggttccatggagactgcatccggatca 1213

 Score = 44.1 bits (22), Expect = 0.066
 Identities = 25/26 (96%)
 Strand = Plus / Plus

Query: 118 gcggaagtagttgtgggcgcctttgc 143
           ||||||||||||| ||||||||||||
Sbjct: 235 gcggaagtagttgcgggcgcctttgc 260

>gb|AC009750.7|AC009750 Drosophila melanogaster, chromosome 2L, region 23F-24A,
BAC clone

 ... 

(file truncated here)



>emb|AL353748.13|AL353748 Human DNA sequence from clone RP11-317B17 on
chromosome 9, complete
             sequence [Homo sapiens]
          Length = 179155

 Score = 38.2 bits (19), Expect = 4.1
 Identities = 22/23 (95%)
 Strand = Plus / Plus

Query: 192   ggcgggggtcgtgagggagtgcg 214
             |||| ||||||||||||||||||
Sbjct: 48258 ggcgtgggtcgtgagggagtgcg 48280

  Database: nt
    Posted date:  May 30, 2001  3:54 AM
  Number of letters in database: -996,408,959
  Number of sequences in database:  868,831

Lambda     K      H
    1.37    0.711     1.31

Gapped
Lambda     K      H
    1.37    0.711     1.31

Matrix: blastn matrix:1 -3
Gap Penalties: Existence: 5, Extension: 2
Number of Hits to DB: 436021
Number of Sequences: 868831
Number of extensions: 436021
Number of successful extensions: 7536
Number of sequences better than 10.0: 19
length of query: 400
length of database: 3,298,558,333
effective HSP length: 20
effective length of query: 380
effective length of database: 3,281,181,713
effective search space: 1246849050940
effective search space used: 1246849050940
T: 0
A: 30
X1: 6 (11.9 bits)
X2: 15 (29.7 bits)
S1: 12 (24.3 bits)
S2: 19 (38.2 bits)
\end{lstlisting}

As you can see, the file consists of three parts: some header information at the beginning followed by a summary of the alignments, the alignments, and then some additional summary parameters and statistics at the end. 

\section{Parsing BLAST Output}
So why parse BLAST output? One reason is to see if your DNA has any new matches against the DNA stored in the constantly growing databases. You can write a program to automatically perform a daily BLAST search and compare its results with those of the previous day by parsing the summary list of hits and comparing it with the previous day's summary list. You can then have the program email you if something new has turned up. 

\subsection{Extracting Annotation and Alignments}
\autoref{exam:example12.1} consists of a main program and two new subroutines. The subroutines—\textit{parse\_blast} and \textit{parse\_blast\_alignment}—use regular expressions to extract the various bits of data from a scalar string. I chose this method because the data, although structured, does not clearly identify each line with its function. (See the discussion in \autoref{chap:chapter10} and \autoref{chap:chapter11}.) 

\textbf{Example 12-1. Extract annotation and alignments from BLAST output file}
\lstinputlisting[label=exam:example12.1]{./scripts/example12-1.pl}

The main program does little more than call the parsing subroutine and print the results. The arguments, initialized as empty, are passed by reference (see \autoref{chap:chapter6}).  

The subroutine \textit{parse\_blast} does the top-level parsing job of separating the three sections of a BLAST output file: the annotation at the beginning, the alignments in the middle, and the annotation at the end.  It then calls the \textit{parse\_blast\_alignment} subroutine to extract the individual alignments from that middle alignment section. The data is first read in from the named file with our old friend the \textit{get\_file\_data} subroutine from \autoref{chap:chapter8}. Use the \textit{join} function to store the array of file data into a scalar string.

The three sections of the BLAST output file are separated by the following statement: 

\begin{lstlisting}
($$beginning_annotation, $alignment_section, $$ending_annotation)

  = ($blast_output_file =~ /(.*^ALIGNMENTS\n)(.*)(^  Database:.*)/ms);
\end{lstlisting}

The pattern match contains three parenthesized expressions: 

\begin{lstlisting}
(.*^ALIGNMENTS\n) 
\end{lstlisting}

which is returned into \verb|$$beginning_annotation;|

\begin{lstlisting}
(.*) 
\end{lstlisting}

which is saved in \verb|$alignment_section;| and:

\begin{lstlisting}
(^  Database:.*) 
\end{lstlisting}

which is saved in \verb|$$ending_annotation|.

The use of \verb|$$| instead of \verb|$| at the beginning of two of these variables indicates that they are references to scalar variables. Recall that they were passed in as arguments to the subroutine, where they were preceded by a backslash, like so: 

\begin{lstlisting}
parse_blast(\$beginning_annotation, \$ending_annotation, \%alignments, $filename);
\end{lstlisting}

You've seen references to variables before, starting in \autoref{chap:chapter6}. Let's review them briefly. Within the \textit{parse\_blast} subroutine, those variables with only one \verb|$| are references to the scalar variables. They need an additional \verb|$| to represent actual scalar variables. This is how references work; they need an additional special character to indicate what kinds of variables they are references to. So a reference to a scalar variable needs to start with \verb|$$|, a reference to an array variable needs to start with \verb|@$|, and a reference to a hash variable needs to start with \verb|%$|. 

The regular expression in the previous code snippet matches everything up to the word \verb|ALIGNMENTS| at the end of a line \verb|(.*^ALIGNMENTS\n)|; then everything for a while \verb|(.*)|; then a line that begins with two spaces and the word \verb|Database|: followed by the rest of the file \verb|(^ Database:.*)|. These three expressions in parentheses correspond to the three desired parts of the BLAST output file; the beginning annotation, the alignment section, and the ending annotation.

The alignments saved in \verb|$alignment_section| are separated out by the subroutine \textit{parse\_blast\_alignment}. This subroutine has one important loop: 

\begin{lstlisting}
while($alignment_section =~ /^>.*\n(^(?!>).*\n)+/gm) {
  my($value) = $&;
  my($key) = (split(/\|/, $value)) [1];
  $alignment_hash{$key} = $value;
}
\end{lstlisting}

You're probably thinking that this regular expression looks downright evil. At first glance, regular expressions do sometimes seem incomprehensible, so let's take a closer look. There are a few new things to examine.

The five lines comprise a \verb|while| loop, which (due to the global \verb|/g| modifier on the pattern match in the \verb|while| loop) keeps matching the pattern as many times as it appears in the string. Each time the program cycles through the loop, the pattern match finds the value (the entire alignment), then determines the key. The key and values are saved in the hash \verb|%alignment_hash|.

Here's an example of one of the matches that's found by this \verb|while| loop when parsing the BLAST output shown in \autoref{sect:section12.3}:

\begin{lstlisting}
>emb|AL353748.13|AL353748 Human DNA sequence from clone RP11-317B17 on
chromosome 9, complete
             sequence [Homo sapiens]
          Length = 179155

 Score = 38.2 bits (19), Expect = 4.1
 Identities = 22/23 (95%)
 Strand = Plus / Plus

Query: 192   ggcgggggtcgtgagggagtgcg 214
             |||| ||||||||||||||||||
Sbjct: 48258 ggcgtgggtcgtgagggagtgcg 48280
\end{lstlisting}

This text starts with a line beginning with a \verb|>| character. In the complete BLAST output, sections like these follow one another. What you want to do is start matching from a line beginning with \verb|>| and include all following adjacent lines that don't start with a \verb|>| character. You also want to extract the identifier, which appears between the first and second vertical bar \verb=|= characters on the first line (e.g., \verb|AL353748.13| in this alignment). 

Let's dissect the regular expression:

\begin{lstlisting}
$alignment_section =~ /^>.*\n(^(?!>).*\n)+/gm
\end{lstlisting}

This pattern match, which appears in a \verb|while| loop within the code, has the modifier \verb|m| for multiline. The \verb|m| modifier allows \verb|^| to match any beginning-of-line inside the multiline string, and \verb|$| to match any end-of-line.

The regular expression breaks down as follows. The first part is:

\begin{lstlisting}
^>.*\n
\end{lstlisting}

It looks for \verb|>| at the beginning of the BLAST output line, followed by \verb|.*|, which matches any quantity of anything (except newlines), up to the first newline. In other words, it matches the first line of the alignment.

Here's the rest of the regular expression:

\begin{lstlisting}
(^(?!>).*\n)+
\end{lstlisting}

After the \verb|^| which matches the beginning of the line, you'll see a \textit{negative lookahead assertion}, \verb|(?!>)|, which ensures that a \verb|>| doesn't follow. Next, the \verb|.*| matches all non-newline characters, up to the final \verb|\n| at the end of the line. All of that is wrapped in parentheses with a surrounding \verb|+|, so that you match all the available lines.

Now that you've matched the entire alignment, you want to extract the key and populate the hash with your key and value. Within the \verb|while| loop, the alignment that you just matched is automatically set by Perl as the value of the special variable \verb|$&| and saved in the variable \verb|$value|. Now you need to extract your key from the alignment. It can be found on the first line of the alignment stored in \verb|$value|, between the first and second \verb=|= symbols.

Extracting this identifying key is done using the \verb|split| function, which
breaks the string into an array. The call to \verb|split|: 

\begin{lstlisting}
split(/\|/, $value)
\end{lstlisting}

splits \verb|$value| into pieces delimited by \verb=|= characters. That is, the \verb=|= symbol is used to determine where one list element ends and the next one begins. (Remember that the vertical bar \verb=|= is a metacharacter and must be escaped as \verb=\|=.) By surrounding the call to split with parentheses and adding an array offset (\verb|[1]|), you can isolate the key and save it into \verb|$key|.

Let's step back now and look at \autoref{exam:example12.1} in its entirety. Notice that it's very short—barely more than two pages, including comments.  Although it's not an easy program, due to the complexity of the regular expressions involved, you can make sense of it if you put a little effort into examining the BLAST output files and the regular expressions that parse it.

Regular expressions have lots of complex features, but as a result, they can do lots of useful things. As a Perl programmer, the effort you put into learning them is well worth it and can have significant payoffs down the road. 

\subsection{Parsing BLAST Alignments}
Let's take the parsing of the BLAST output file a little further. Notice that some of the alignments include more than one aligned string—for instance, the alignment for ID AK017941.1, shown again here: 

\begin{lstlisting}
>dbj|AK017941.1|AK017941 Mus musculus adult male thymus cDNA, RIKEN
full-length enriched
            library, clone:5830420C16, full insert sequence
          Length = 1461

 Score =  210 bits (106), Expect = 5e-52
 Identities = 151/166 (90%)
 Strand = Plus / Plus

Query: 235  ggagatggttcagacccagagcctccagatgccggggaggacagcaagtccgagaatggg 294
            |||||||| |||||||  || ||||| ||||||||||| ||||||||||| |||||||||
Sbjct: 1048 ggagatggctcagacctggaacctccggatgccggggacgacagcaagtctgagaatggg 1107

Query: 295  gagaatgcgcccatctactgcatctgccgcaaaccggacatcaactgcttcatgatcggg 354
            ||||| || ||||||||||||||||| ||||||||||||||||| ||||||||||| ||
Sbjct: 1108 gagaacgctcccatctactgcatctgtcgcaaaccggacatcaattgcttcatgattgga 1167

Query: 355  tgtgacaactgcaatgagtggttccatggggactgcatccggatca 400
            |||||||||||||| |||||||||||||| ||||||||||||||||
Sbjct: 1168 tgtgacaactgcaacgagtggttccatggagactgcatccggatca 1213

 Score = 44.1 bits (22), Expect = 0.066
 Identities = 25/26 (96%)
 Strand = Plus / Plus

Query: 118 gcggaagtagttgtgggcgcctttgc 143
           ||||||||||||| ||||||||||||
Sbjct: 235 gcggaagtagttgcgggcgcctttgc 260
\end{lstlisting}

To parse these alignments, we have to parse out each of the matched strings, which in BLAST terminology are called \textit{high-scoring pairs} (HSPs).

Each HSP also contains some annotation, and then the HSP itself. Let's parse each HSP into annotation, query string, and subject string, together with the starting and ending positions of the strings. More parsing is possible; you can extract specific features of the annotation, as well as the locations of identical and nonidentical bases in the HSP, for instance.

\autoref{exam:example12.2} includes a pair of subroutines; one to parse the alignments into their HSPs, and the second to extract the sequences and their end positions. The main program extends \autoref{exam:example12.1} using these new subroutines. 

\textbf{Example 12-2. Parse alignments from BLAST output file}
\lstinputlisting[label=exam:example12.2]{./scripts/example12-2.pl}

\autoref{exam:example12.2} gives the following output:

\begin{lstlisting}
-> Expect value:   5e-52

-> Query string:
ggagatggttcagacccagagcctccagatgccggggaggacagcaagtccgagaatggg
gagaatgcgcccatctactgcatctgccgcaaaccggacatcaactgcttcatgatcgggtgtgacaactgcaatgagt
ggttccatggggactgcatccggatca

-> Query range:    235..400

-> Subject String:
ctggagatggctcagacctggaacctccggatgccggggacgacagcaagtctgagaatg
ggctgagaacgctcccatctactgcatctgtcgcaaaccggacatcaattgcttcatgattggacttgtgacaactgca
acgagtggttccatggagactgcatccggatca

-> Subject range:  1048..1213
\end{lstlisting}

Let's discuss the new features of \autoref{exam:example12.2} and its subroutines.  First notice that the two new subroutines from \autoref{exam:example12.1} have been placed into the \textit{BeginPerlBioinfo.pm} module, so they aren't printed again here.

The main program, \autoref{exam:example12.2}, starts the same as \autoref{exam:example12.1}; it calls the \textit{parse\_blast} subroutine to separate the annotation from the alignments in the BLAST output file.

The next line fetches one of the alignments from the \verb|%alignments| hash, which is then used as the argument to the \textit{parse\_blast\_alignment\_HSP} subroutine, which then returns an array of annotation (as the first element) and HSPs in \verb|@HSPs|. Here you see that not only can a subroutine return an array on a scalar value; it can also return a hash.

Finally, \autoref{exam:example12.2} does the lower-level parsing of an individual HSP by calling the \textit{extract\_HSP\_information} subroutine, and the extracted parts of one of the HSPs are printed.

\autoref{exam:example12.2} shows a certain inconsistency in our design. Some subroutines call their arguments by reference; others call them by value (see \autoref{chap:chapter6}). You may ask: is this a bad thing?

The answer is: not necessarily. The subroutine \textit{parse\_blast} mixes several arguments, and one of them is not a scalar type. Recall that this is a potentially good place to use call-by-reference in Perl. The other subroutines don't mix argument types this way. However, they can be designed to call their arguments by reference.

Continuing with the code, let's examine the subroutine \textit{parse\_blast\_alignment\_HSP}. This takes one of the alignments from the BLAST output and separates out the individual HSP string matches. The technique used is, once again, regular expressions operating on a single string that contains all the lines of the alignment given as the input argument.

The first regular expression parses out the annotation and the section containing the HSPs: 

\begin{lstlisting}
($beginning_annotation, $HSP_section )

= ($alignment =~ /(.*?)(^ Score =.*)/ms);
\end{lstlisting}

The first parentheses in the regular expression is \verb|(.*?)| This is the nongreedy or minimal matching mentioned in \autoref{chap:chapter9}. Here it gobbles up everything before the first line that begins \verb|Score =| (without the \verb|?| after the \verb|*|, it would gobble everything until the final line that begins \verb|Score =|). This is the exact dividing line between the beginning annotation and the HSP string matches.

The next loop and regular expression separates the individual HSP string matches: 

\begin{lstlisting}
while($HSP_section =~ /(^ Score =.*\n)(^(?! Score =).*\n)+/gm) {
  
  push(@HSPs, $&);

}
\end{lstlisting}

This is the same kind of global string match in a \verb|while| loop you've seen
before; it keeps iterating as long as the match can be found. The other
modifier \verb|/m| is the multiline modifier, which enables the metacharacters
\verb|$| and \verb|^| to match before and after embedded newlines.

The expression within the first pair of parentheses—\verb|(^ Score =.*\n)|—matches a line that begins \verb|Score =|, which is the kind of line that begins an HSP string match section.

The code within the second pair of parentheses—\verb|(^(?! Score =).*\n)+|—matches one or more (the \verb|+| following the other parentheses) lines that do not begin with \verb|Score =|. The \verb|?!| at the beginning of the embedded parentheses is the negative lookahead assertion you encountered in \autoref{exam:example12.2}. So, in total, the regular expression captures a line beginning with \verb|Score =| and all succeeding adjacent lines that don't begin with \verb|Score =|. 

\section{Presenting Data}
Up to now, we've relied on the \textit{print} statement to format output. In this section, I introduce three additional Perl features for writing output:

\begin{itemize}
  \item \textit{printf} function
  \item \textit{here} documents
  \item \textit{format} and \verb|write| functions
\end{itemize}

The entire story about these Perl output features is beyond the scope of this book, but I'll tell you just enough to give you an idea of how they can be used.  

\subsection{The printf Function}
The \textit{printf} function is like the \textit{print} function but with extra features that allow you to specify how certain data is printed out. Perl's \textit{printf} function is taken from the C language function of the same name. Here's an example of a \textit{printf} statement: 

\begin{lstlisting}
my $first  = '3.14159265';
my $second  = 76;
my $third = "Hello world!";

printf STDOUT "A float: %6.4f An integer: %-5d and a string: %s\n", 
     $first, $second,  $third;
\end{lstlisting}

This code snippet prints the following:

\begin{lstlisting}
A float:  3.1416 An integer: 76    and a string: Hello world!
\end{lstlisting}

The arguments to the \textit{printf} function consist of a format string, followed by a list of values that are printed as specified by the format string. The format string may also contain any text along with the directives to print the list of values. (You may also specify an optional filehandle in the same manner you would a \verb|print| function.)

The directives consist of a percent sign followed by a required conversion specifier, which in the example includes \verb|f| for floating point, \verb|d| for integer, and \verb|s| for string. The conversion specifier indicates what kind of data is in the variable to be printed. Between the \verb|%| and the conversion specifier, there may be 0 or more flags, an optional minimum field width, an optional precision, and an optional length modifier. The list of values following the format string must contain data that matches the types of directives, in order.

There are many possible options for these flags and specifiers (some are listed in \autoref{chap:chapterab}). Here's what is in \autoref{exam:example12.3}. First, the directive \verb|%6.4f| specifies to print a floating point (that is, a decimal) number, with a minimum width of six characters overall (padded with spaces if necessary), and at most four positions for the decimal part.  You see in the output that, although the \verb|$f| floating-point number gives the value of pi to eight decimal places, the example specifies a precision of four decimal places, which are all that is printed out.  

The \verb|%-5d| directive specifies an integer to be printed in a field of width 5; the - flag causes the number to be left-justified in the field.  Finally, the \verb|%s| directive prints a string.  

\subsection{here Documents}
Now we'll briefly examine \verb|here| documents. These are convenient ways to specify multiline text for output with perhaps some variables to be interpolated, in a way that looks pretty much the same in your code as it will in the output—that is, without a lot of \verb|print| statements or embedded newline \verb|\n| characters. We'll follow \autoref{exam:example12.3} and its output with a discussion. 

\textbf{Example 12-3. Example of here document}
\lstinputlisting[label=exam:example12.3]{./scripts/example12-3.pl}

Here's the output from \autoref{exam:example12.3}:

\begin{lstlisting}
On iteration 0 of the loop!
AAACCCCCCGGGGGGGGTTTTTT

On iteration 1 of the loop!
AAACCCCCCGGGGGGGGTTTTTT
\end{lstlisting}

In \autoref{exam:example12.3}, a \verb|here| document was put in a \textit{for} loop, so that you can see the \verb|$i| variable changing in the printout. The variables are interpolated into a \verb|here| document in the same way they are interpolated into a double-quoted string. Every time they go through the loop, the contents of the \verb|here| document are subject to variable interpolation and are printed out. The terminating string used in this example, HEREDOC, can be any string you specify. (There are several options for dealing with things like indentation and so forth; I won't discuss them here and refer you to the Perl documentation.) Here documents are handy for some tasks, such as when you have a long, multiline document with just a few changes applied each time you print it. A business form letter, with only the addressee changed, is a typical example. Using a \verb|here| document preserves the look of the final output in the code, while allowing variable interpolation.

\subsection{format and write}
Finally, let's take a look at the \textit{format} and \textit{write} functions. \verb|format| is designed to generate reports and can handle page numbers, headers, and various layout options such as centering and left and right justification. It's modelled on the FORTRAN programming-language conventions for formatting and so is particularly handy for producing reports based on that style, such as the PDB file format, in which fields are specified as occupying certain columns on the line.

\autoref{exam:example12.4} is a short example of a format that creates a FASTA-style output. 

\textbf{Example 12-4. Example of format function to produce FASTA output}
\lstinputlisting[label=exam:example12.4]{./scripts/example12-4.pl}

Here's the output of \autoref{exam:example12.4}:

\begin{lstlisting}
>A0000      Highly unlikely DNA.  This DNA is so\ldots
AAAAAACCCCCCCCCCCCCCGGGGGGGGGGGGGGGGGGGGGGTTTTTTTTT
TTTTTTTTTTTT
\end{lstlisting}

After declaring and initializing the variables that fill in the form, the form is defined with: 

\begin{lstlisting}
format STDOUT =
\end{lstlisting}

and the format continues until it reaches the line with a period at the beginning.

The format is composed of three kinds of lines:

\begin{itemize}
  \item A comment beginning with the pound sign \verb|#|
  \item A picture line that specifies the layout of text
  \item An argument line that names the variables that fill in the preceding picture line
\end{itemize}

The picture line and the argument line must be adjacent; they can't be separated by a comment line, for instance.

The first picture line/argument line combo is for the header information: 

\begin{lstlisting}
>@<<<<<<<<< @<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<...
$id,        $description
\end{lstlisting}

The picture line has two picture fields in it, associated with the variables \verb|$id| and \verb|$description|, respectively. The picture line begins with a greater-than sign, \verb|>|, which is just text that begins each FASTA file header line, by definition. Then comes the first picture field, which is an \verb|@| sign followed by nine \verb|<| signs. The \verb|@| sign declares a field that has the associated variable interpolated into it. The use of the nine less-than signs specifies that the value should be left-justified, for a total of 10 columns. If the value is bigger than 10 columns, it is truncated. A less-than sign left-justifies, a greater-than sign right-justifies, and a vertical bar \verb=|= centers the data in the field.

The second picture field is almost identical. It is longer and ends with three dots (an ellipsis) which prints if the contents of the variable \verb|$description| can't fit into the length of the picture field (which, in this case, is true.)

The next pair of picture/argument lines is:

\begin{lstlisting}
^<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<~~
$DNA
\end{lstlisting}

The picture field starts with a caret, which declares a picture field that will handle variable-length records. The line also contains 49 less-than signs, for a total of 50 columns, left-justified. At the end are two tilde \verb|~| signs, which indicate there should be additional lines for the data if it doesn't fit one on one line.

The \verb|write| command simply prints the previously defined format. By default, the output goes to STDOUT, as is done in the example, but you can supply a filehandle to the \verb|format| and \verb|write| statements if you desire.

The upcoming release of Perl 6 will move formats out of the core of the language and make them into a module. Details are not available as of this writing, but this change will probably entail adding a statement such as \verb|use Formats;| near the top of your code in order to load the module for using formats.

\section{Bioperl}
The \textit{Bioperl} project is an important collection of Perl code for bioinformatics that has been in development since 1998. Although Bioperl uses the more advanced object-oriented style of Perl program design, it's possible to take an introductory look here at how it's organized and used.

The main focus of Bioperl modules is to perform sequence manipulation, provide access to various biology databases (both local and web-based), and parse the output of various programs.

Bioperl is available at \href{http://www.bioperl.org/}{http://www.bioperl.org/}. Some of its features rely on having additional Perl modules—available from CPAN (\href{http://www.cpan.org/}{http://www.cpan.org/})—installed. This situation is quite common, and as you do more Perl programming, you'll become familiar with installing modules from CPAN. The Bioperl tutorials include information on installing Bioperl and additional modules for the three major operating systems: Unix or Linux, Mac, and Windows.

Bioperl doesn't provide complete programs. Rather, it provides a fairly large—and growing—set of modules for accomplishing common tasks, including some tasks you've seen in this book. You're responsible for writing the code that holds the modules together. By providing these ready and (usually) easy-to-use modules, Bioperl makes developing bioinformatics applications in Perl faster and easier. There are example programs for most of the modules, which can be examined and modified to get started.

Like many open source projects, Bioperl has suffered from fragmentation and uneven documentation, due to the strictly volunteer and geographically dispersed group of contributors. But recent work on the project leading up to Release 0.7 in March 2001 has significantly improved the project. In particular, there is now enough tutorial information on using the modules to enable you to make good use of the code.

Some difficulties still remain. Most of the code has been developed on Unix or Linux systems. Not all of it works on Macs or Windows operating systems, but most will. There are some documents available at the Bioperl web site that discuss using Bioperl on non-Unix computers, but the bottom line is that you might find that some things don't work.

If you're going to give Bioperl a try (and I strongly recommend you do), you should make sure you have a fairly recent version of Perl installed.  You'll need at least Version 5.004; it would be much better to install the latest stable release from the Perl web site \href{http://www.perl.com}{http://www.perl.com}. 

\subsection{Sample Modules}
To give you an idea of what tasks Bioperl can make easier for you, \autoref{tab:table12.1} displays a representative sample of some of the most useful modules available. 

\begin{table}[!htbp]
  \begin{center}
  \caption{Bioperl modules}
  \label{tab:table12.1}
  \begin{tabu}{X[2,l]X[3,l]}
  \toprule
  Module & Description\\
  \midrule
  Bio::Seq & Sequence object, with features\\
  Bio::SimpleAlign & Multiple alignments held as a set of sequences\\
  Bio::Species & Generic species object\\
  Bio::DB::Ace & Database object interface to ACeDB servers\\
  Bio::DB::GDB & Database object interface to GDB HTTP query\\
  Bio::DB::GenBank & Database object interface to GenBank\\
  Bio::DB::GenPept & Database object interface to GenPept\\
  Bio::DB::NCBIHelper & A collection of routines useful for queries to NCBI databases\\
  Bio::DB::SwissProt & Database object interface to SWISS-PROT retrieval\\
  Bio::Index::Fasta & Interface for indexing FASTA files\\
  Bio::Index::GenBank & Interface for indexing GenBank seq files, that is, flat files in GenBank format\\
  Bio::Location::Simple & Implementation of a simple location on a sequence\\
  Bio::Location::Split & Implementation of a location on a sequence that has multiple locations\\
  Bio::SeqFeature::FeaturePair & Holds pair feature information, e.g., BLAST hits\\
  Bio::SeqFeature::Generic & Generic SeqFeature\\
  Bio::SeqFeature::Similarity & Sequence feature based on similarity\\
  Bio::SeqFeature::SimilarityPair & Sequence feature based on the similarity of two sequences\\
  Bio::SeqFeature::Gene::Exon & Feature representing an exon\\
  Bio::SeqFeature::Gene::GeneStructure & Feature representing an arbitrarily complex structure of a gene\\
  Bio::SeqFeature::Gene::Transcript & Feature representing a transcript\\
  Bio::SeqFeature::Gene::TranscriptI & Interface for a feature representing a transcript of exons, promoter, UTR, and a poly-adenylation site\\
  Bio::Tools::Blast & Bioperl BLAST sequence analysis object\\
  Bio::Tools::BPbl2seq & Lightweight BLAST parser for pair-wise sequence alignment using the BLAST algorithm\\
  Bio::Tools::BPlite &  Lightweight BLAST parser\\
  Bio::Tools::BPpsilite & Lightweight BLAST parser for PSIBLAST reports\\
  Bio::Tools::CodonTable & Bioperl codon table object\\
  Bio::Tools::Fasta & Bioperl FASTA utility object\\
  Bio::Tools::IUPAC & Generates unique seq objects from an ambiguous seq object\\
  Bio::Tools::RestrictionEnzyme & Bioperl object for a restriction endonuclease object\\
  Bio::Tools::SeqPattern & Bioperl object for a sequence pattern or motif\\
  Bio::Tools::SeqStats & Object holding statistics for one particular sequence\\
  Bio::Tools::SeqWords & Object holding n-mer statistics for one sequence\\
  Bio::Tools::Blast::HSP & Bioperl BLAST high-scoring segment pair object\\
  Bio::Tools::Blast::HTML & Bioperl utility module for HTML-formatting BLAST reports\\
  Bio::Tools::Blast::Sbjct & Bioperl BLAST "hit" object\\
  Bio::Tools::Blast::Run::LocalBlast & Bioperl module for running BLAST analyses locally\\
  Bio::Tools::Blast::Run::Webblast & Bioperl module for running BLAST analyses using an HTTP interface\\
  Bio::Tools::Prediction::Exon & Predicted exon feature\\
  Bio::Tools::Prediction::Gene & Predicted gene structure feature\\
  Bio::Variation::AAChange & Sequence change class for polypeptides\\
  Bio::Variation::AAReverseMutate & Point mutation and codon information from single amino acid changes\\
  Bio::Variation::Allele & Sequence object with allele-specific attributes\\
  Bio::Variation::DNAMutation & DNA-level mutation class\\
  Bio::Variation::IO & Handler for sequence variation I/O formats\\
  \bottomrule
  \end{tabu}
  \end{center}
\end{table}

\subsection{Bioperl Tutorial Script}
Bioperl has a tutorial script to help you try out various parts of the package. In this section, I'll show how to start up and run some example computations.

I've mentioned already that you should learn how to download code from CPAN in order to add modules such as Bioperl. A great deal of the usefulness of the Perl programming environment now resides in these modules available on CPAN. This was a design decision: by concentrating on the core Perl language, the Perl designers can focus on making the language as good as they can. The Perl module developers can then concentrate on their many modules. By all means, take a look around the CPAN web site for an idea of the wealth of Perl modules available to you.

I won't give the details of how to install Bioperl here: as mentioned, they are available at the Bioperl web site, or you can visit the CPAN web site for information.  

So, let's assume you've installed the Bioperl module and looked over the tutorial at the Bioperl web site. Now, let's see how to try out some Bioperl programs.

Go to the directory where the Bioperl software has been built on your system. For instance, on my Linux computer, I put the download file \textit{bioperl-0.7.0.tar.gz} into the directory \textit{/usr/local/src}, and then unpacked it with the command: 

\begin{lstlisting}[language=bash]
tar xvzf bioperl-0.7.0.tar.gz
\end{lstlisting}

which creates the source directory \textit{/usr/local/src/bioperl-0.7.0}. After installing the module (check the documentation), you're ready to run the tutorial script.

Change to the source directory and type \verb|perl bptutorial.pl|. Here's the result (I've shown the head of the tutorial to give the author and copyright information): 

\begin{lstlisting}
% head bptutorial.pl 
# $Id: ch12,v 1.44 2001/10/10 20:37:42 troutman Exp mam $

=head1  BioPerl Tutorial

  Cared for by Peter Schattner <schattner@alum.mit.edu>

  Copyright Peter Schattner

   This tutorial includes "snippets" of code and text from various
   Bioperl documents including module documentation, example scripts
% perl bptutorial.pl 

The following numeric arguments can be passed to run the corresponding demo-script.
1 => access_remote_db ,
2 => index_local_db ,
3 => fetch_local_db ,               (# NOTE: needs to be run with demo 2)
4 => sequence_manipulations ,
5 => seqstats_and_seqwords ,
6 => restriction_and_sigcleave ,
7 => other_seq_utilities ,
8 => run_standaloneblast ,
9 => blast_parser ,
10 => bplite_parsing ,
11 => hmmer_parsing ,
12 => run_clustalw_tcoffee ,
13 => run_psw_bl2seq ,
14 => simplealign_univaln ,
15 => gene_prediction_parsing ,
16 => sequence_annotation ,
17 => largeseqs ,
18 => liveseqs ,
19 => demo_variations ,
20 => demo_xml ,

In addition the argument "100" followed by the name of a single
bioperl object will display a list of all the public methods
available from that object and from what object they are inherited.

Using the parameter "0" will run all tests.
Using any other argument (or no argument) will run this display.

So typical command lines might be:
To run all demo scripts:
 > perl -w  bptutorial.pl 0
or to just run the local indexing demos:
 > perl -w  bptutorial.pl 2 3
or to list all the methods available for object Bio::Tools::SeqStats -
 > perl -w  bptutorial.pl 100 Bio::Tools::SeqStats

%
\end{lstlisting}

Now let's try option 9, the BLAST parser, and option 1, \verb|access_remote_db|. So here goes, starting with the BLAST parser: 

\begin{lstlisting}
% perl bptutorial.pl 9

Beginning blast.pm parser example... 

QUERY NAME     : gi|1401126
QUERY DESC     : UNKNOWN
LENGTH         : 504
FILE           : t/blast.report
DATE           : Thu, 16 Apr 1998 18:56:18 -0400
PROGRAM        : TBLASTN
VERSION        : 2.0.4 [Feb-24-1998]</b>
DB-NAME        : Non-redundant GenBank+EMBL+DDBJ+PDB sequences
DB-RELEASE     : Apr 16, 1998  9:38 AM
DB-LETTERS     : 677679054
DB-SEQUENCES   : 336723
GAPPED         : YES
TOTAL HITS     : 100
CHECKED ALL    : YES
FILT FUNC      : NO
SIGNIF HITS    : 4
SIGNIF CUTOFF  : 1.0e-05 (EXPECT-VALUE)
LOWEST EXPECT  : 0.0
HIGHEST EXPECT : 1e-05
HIGHEST EXPECT : 7.6 (OVERALL)
MATRIX         : BLOSUM62
FILTER         : NONE
EXPECT         : 10
LAMBDA, K, H   : 0.270, 0.0470, 0.230 (SHARED STATS)
WORD SIZE      : 13
S              : 42, 74 (SHARED STATS)
GAP CREATION   : 11
GAP EXTENSION  : 1

Number of hits is 4 
Fraction identical for hit 1 is 0.25 
Sequence identities for hsp of hit 1 are 66-68 70 73 76 79 80 87-89 114 117
119 131 144 146 149 150 152 156 162 165 168 170 171 176 178-182 184 187 190
191 205-207 211 214 217 222 226 241 244 245 249 256 266-268 270 278 284 291
296 304 306 309 311 316 319 324 
%
\end{lstlisting}

This is an interesting way to parse BLAST output! Now let's look at the access of the remote DB: 

\begin{lstlisting}
% perl bptutorial.pl 1
Beginning remote database access example... 
seq1 display id is MUSIGHBA1 
seq2 display id is AF303112 
Display id of first sequence in stream is AF041456
% 
\end{lstlisting}

Well, that was less informative as an output, but it seems you can infer that the remote DB access was successful. (By the way, if you're unsuccessful with this, it may be that you're behind a firewall which is denying access—a not uncommon occurrence in universities or large companies.)

The documentation suggests running the \textit{bptutorial.pl} script under the Perl debugger to watch what happens step by step. I concur with that suggestion but won't include the output here. Try it yourself!

Since that last example wasn't much fun, let's try one more: here's the sequence manipulation tutorial: 

\begin{lstlisting}
% perl bptutorial.pl 4

Beginning sequence_manipulations and SeqIO example... 
First sequence in fasta format... 
>Test1
AGCTTTTCATTCTGACTGCAACGGGCAATATGTCTCTGTGTGGATTAAAAAAAGAGTGTC
TGATAGCAGCTTCTGAACTGGTTACCTGCCGTGAGTAAATTAAAATTTTATTGACTTAGG
TCACTAAATACTTTAACCAATATAGGCATAGCGCACAGACAGATAAAAATTACAGAGTAC
ACAACATCCATGAAACGCATTAGCACCACC
Seq object display id is Test1
Sequence is AGCTTTTCATTCTGACTGCAACGGGCAATATGTCTCTGTGTGGATTAAAAAAAGAGTGTCTGATAG
CAGCTTCTGAACTGGTTACCTGCCGTGAGTAAATTAAAATTTTATTGACTTAGGTCACTAAATACTTTAACCAATATA
GGCATAGCGCACAGACAGATAAAAATTACAGAGTACACAACATCCATGAAACGCATTAGCACCACC 
Sequence from 5 to 10 is TTTCAT 
Acc num is unknown 
Moltype is dna 
Primary id is Test1 
Truncated Seq object sequence is TTTCAT 
Reverse complemented sequence 5 to 10  is GTGCTA  
Translated sequence 6 to 15 is LQRAICLCVD 

Beginning 3-frame and alternate codon translation example... 
ctgagaaaataa translated using method defaults   : LRK*
ctgagaaaataa translated as a coding region (CDS): MRK

Translating in all six frames:
 frame: 0 forward: LRK*
 frame: 0 reverse-complement: LFSQ
 frame: 1 forward: *ENX
 frame: 1 reverse-complement: YFLX
 frame: 2 forward: EKI
 frame: 2 reverse-complement: IFS
Translating with all codon tables using method defaults:
1 : LRK*
2 : L*K*
3 : TRK*
4 : LRK*
5 : LSK*
6 : LRKQ
9 : LSN*
10 : LRK*
11 : LRK*
12 : SRK*
13 : LGK*
14 : LSNY
15 : LRK*
16 : LRK*
21 : LSN*
% 
\end{lstlisting}

That was more fun, because this part of Bioperl is doing several things we've done in this book.

I hope this brief look at Bioperl has whetted your appetite for more.  It's a good idea to explore this set of modules. A Perl module for parsing BLAST output called \textit{BPLite.pm} may also be of interest: it's now part of the Bioperl project. 

\section{Exercises}
\textcolor{red}{\textit{Exercise 12.1}}
\begin{adjustwidth}{1cm}{}
  \textit{Basic string matching}. Write a program that looks for a query string in a target string. For instance, if the query string is "gone", it finds a match at position 22 of the target string "goof through the way-gone-osphere." Don't use regular expressions or any of Perl's built-in string-matching abilities; instead, examine individual positions in the strings, compare characters, and invent your own algorithm. 
\end{adjustwidth}

\textcolor{red}{\textit{Exercise 12.2}}
\begin{adjustwidth}{1cm}{}
  Explore the NCBI BLAST web pages at \href{http://www.ncbi.nlm.nih.gov/BLAST}{http://www.ncbi.nlm.nih.gov/BLAST}. Familiarize yourself with the purpose and use of the various component programs and read the tutorial information on the meaning of the statistics. 
\end{adjustwidth}

\textcolor{red}{\textit{Exercise 12.3}}
\begin{adjustwidth}{1cm}{}
  Explore the Bioperl web pages at \href{http://www.bioperl.org}{http://www.bioperl.org}. Download the code and install it on your computer. 
\end{adjustwidth}

\textcolor{red}{\textit{Exercise 12.4}}
\begin{adjustwidth}{1cm}{}
Perform BLAST searches at the NCBI web site. Search with DNA against DNA databases; then search with the same DNA against protein databases, and compare the output.
\end{adjustwidth}

\textcolor{red}{\textit{Exercise 12.5}}
\begin{adjustwidth}{1cm}{}
Perform two BLAST searches with related sequences. Parse the BLAST output of the searches and extract the top 10 hits in the header annotation of each search. Write a program that reports on the differences and similarities between the two searches.
\end{adjustwidth}

\textcolor{red}{\textit{Exercise 12.6}}
\begin{adjustwidth}{1cm}{}
Write a program that uses Bioperl to perform a BLAST search at the NCBI web site, then use Bioperl to parse the BLAST output. 
\end{adjustwidth}

\textcolor{red}{\textit{Exercise 12.7}}
\begin{adjustwidth}{1cm}{}
Using Bioperl modules mixed with your own code, write a program that runs BLAST on a set of DNA sequences and saves the IDs of the list of hits of each BLAST run sorted in arrays. Allow the user to view each list, to view hits in common between multiple lists and hits unique to one of multiple lists. For each hit, enable the user to fetch its entire GenBank record. 
\end{adjustwidth}

\textcolor{red}{\textit{Exercise 12.8}}
\begin{adjustwidth}{1cm}{}
Write an explanation of the code for the subroutine \textit{extract\_HSP\_information}. Be sure to refer to the format of the data the code uses as input. 
\end{adjustwidth}

